{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-01T07:25:27.020293Z",
     "start_time": "2025-12-01T07:25:26.391784Z"
    }
   },
   "source": [
    "import deepSI_jax\n",
    "from deepSI_jax import get_nu_ny_and_auto_norm\n",
    "from deepSI_jax.utils import find_best_model, RMS_error\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data generation\n",
    "To demonstrate the parallel training option, we generate a simple data-set, similar to the previous examples."
   ],
   "id": "93dcbadc0f05ae41"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T07:25:31.554601Z",
     "start_time": "2025-12-01T07:25:31.536971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate or load data\n",
    "np.random.seed(0)  # for reproducibility\n",
    "U = np.random.randn(10000)  # Input sequence\n",
    "x = [0, 0]  # Initial state\n",
    "ylist = []  # Output sequence\n",
    "for uk in U:\n",
    "    ek = np.random.normal(loc=0, scale=0.05)\n",
    "    ylist.append(x[0] + ek)  # Compute output\n",
    "    x = x[0] / (1.2 + x[1]**2) + x[1] * 0.4, \\\n",
    "        x[1] / (1.2 + x[0]**2) + x[0] * 0.4 + uk  # Advance state\n",
    "Y = np.array(ylist)  # Output sequence\n",
    "\n",
    "# Split datasets\n",
    "Y_train = Y[:9000]\n",
    "Y_test = Y[9000:]\n",
    "U_train = U[:9000]\n",
    "U_test = U[9000:]"
   ],
   "id": "7615a669b2f29181",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model initialization\n",
    "The same principle can be followed for model initialization, with an important difference: the `seed` argument now must be a list with all the initial seeds that will correspond to all the different model initializations."
   ],
   "id": "7f4f252e85013c83"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T07:25:45.672256Z",
     "start_time": "2025-12-01T07:25:44.848398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nu, ny, norm = get_nu_ny_and_auto_norm(Y_train, U_train)\n",
    "nx = 3\n",
    "f_dict = dict(hidden_layers=2, nodes_per_layer=32, activation='tanh')\n",
    "h_dict = dict(feedthrough=False)\n",
    "seeds = [1, 2, 3]\n",
    "model = deepSI_jax.SUBNET(nx=nx, ny=ny, nu=nu, norm=norm, f_args=f_dict, h_args=h_dict, use_encoder=False, seed=seeds)\n",
    "\n",
    "model.set_loss_fun(T=250, T_overlap=50, l2_reg=1e-4)\n",
    "\n",
    "model.optimization(adam_epochs=200, lbfgs_epochs=200, iprint=-1)  # similarly as before, the iteration numbers can be increased for more accurate results"
   ],
   "id": "4254ef2bddf29c3c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Parallel training\n",
    "To initiate parallel training of multiple models, instead of calling the `fit` method of the model, now the `fit_parallel` function needs to be called. here you can also specify the number of training samples that are started at the same time with the `n_jobs` argument that utilizes the maximum available CPU cores by default. Keep in mind that the `fit_parallel` function returns a list of all trained models."
   ],
   "id": "6f0bbdc40e7b97d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T07:26:08.665560Z",
     "start_time": "2025-12-01T07:25:53.983819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train model on data\n",
    "models = model.fit_parallel(Y_train, U_train, seeds)"
   ],
   "id": "1959cbc95da881e9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L-BFGS-B done in 172 iterations.\n",
      "L-BFGS-B done in 172 iterations.\n",
      "L-BFGS-B done in 183 iterations.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After all models have been trained, we can select the best-performing one based on the training or test errors. We can simply iterate along them and simulate each model on the selected data-set, but there is also a built-in function for that, namely the `deepSI_jax.utils.find_best_model`. This function also simulated the models in parallel for a more time-efficient evaluation process.",
   "id": "ffeefbfe074c129d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T07:26:18.412847Z",
     "start_time": "2025-12-01T07:26:17.129089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# evaluate models on test data to find best\n",
    "# (this method estimates the initial state values in a highly approximated manner only to compare models)\n",
    "best_model = find_best_model(models, Y_test, U_test, seeds=seeds)"
   ],
   "id": "e53323dba1a86bac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[F\n",
      "RTS smoothing, epoch:   1/  1, MSE loss =  0.030045\n",
      "\u001B[F\n",
      "RTS smoothing, epoch:   1/  1, MSE loss =  0.018657\n",
      "\u001B[F\n",
      "RTS smoothing, epoch:   1/  1, MSE loss =  0.030966\n",
      "\n",
      "Final loss MSE (after LBFGS refinement) =  0.017947\n",
      "\n",
      "Final loss MSE (after LBFGS refinement) =  0.029426\n",
      "Final loss MSE (after LBFGS refinement) =  0.030356\n",
      "\n",
      "Errors:\n",
      "Model 0: RMSE = 0.13089488446712494\n",
      "Model 1: RMSE = 0.10222359001636505\n",
      "Model 2: RMSE = 0.13294817507266998\n",
      "Best model: 1, score: 0.10222359001636505 at seed 2\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "When the model does not contain an encoder network, the `find_best_model` function roughly estimates the initial states for all models, but after finding the bets-performing structure, a more sophisticated state estimation process is advised, e.g., see below. There are various other options for the  `find_best_model` method that are well documented in the docstring, for example, if the models are compared on the training data-set, the optimized initial states can be used that have been tuned during model training. We will also show an example with a trained encoder network later in this Example.",
   "id": "b93742e859cd25a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T07:26:34.250651Z",
     "start_time": "2025-12-01T07:26:33.221399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# evaluate the best model (with a more enhanced initial state estimation method)\n",
    "x0_test = best_model.learn_x0(U_test, Y_test, RTS_epochs=10, LBFGS_refinement=True, verbosity=False)\n",
    "Yhat_test, _ = best_model.simulate(x0_test, U_test)\n",
    "error = RMS_error(Y_test, Yhat_test)\n",
    "\n",
    "print(f'RMS error: {error:.4f}')"
   ],
   "id": "b0f43a0ff8f71e97",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS error: 0.1022\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Training encoder networks in parallel\n",
    "To initialize and train structures with encoders in parallel, the same process can be applied as before."
   ],
   "id": "273158d081971c36"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T07:26:55.766096Z",
     "start_time": "2025-12-01T07:26:42.303576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder_dict = dict(hidden_layers=2, nodes_per_layer=16, activation='swish')\n",
    "n_lag = 20\n",
    "model = deepSI_jax.SUBNET(nx=nx, ny=ny, nu=nu, norm=norm, f_args=f_dict, h_args=h_dict, use_encoder=True, encoder_args=encoder_dict, encoder_lag=n_lag, seed=seeds)\n",
    "\n",
    "model.set_loss_fun(T=250, T_overlap=50, l2_reg=1e-4)\n",
    "model.optimization(adam_epochs=200, lbfgs_epochs=200, iprint=-1)  # only to run fast\n",
    "\n",
    "# Train model on data\n",
    "models = model.fit_parallel(Y_train, U_train, seeds)"
   ],
   "id": "765ec120cee6ca31",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L-BFGS-B done in 176 iterations.\n",
      "L-BFGS-B done in 178 iterations.\n",
      "L-BFGS-B done in 178 iterations.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, we can set the `use_encoder` flag of the `find_best_model` function to `True` in order to utilize the encoders when comparing all models.",
   "id": "763cbac9ae0f4d7b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T07:27:04.303166Z",
     "start_time": "2025-12-01T07:27:03.563668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# evaluate models on test data to find best\n",
    "# (now we can use the encoder to estimate the initial states)\n",
    "best_model = find_best_model(models, Y_test, U_test, seeds=seeds, use_encoder=True)"
   ],
   "id": "8aa6325e1b5799f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors:\n",
      "Model 0: RMSE = 0.11667755246162415\n",
      "Model 1: RMSE = 0.09886123985052109\n",
      "Model 2: RMSE = 0.10618513822555542\n",
      "Best model: 1, score: 0.09886123985052109 at seed 2\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And again, the found best model can be evaluated as before.",
   "id": "1b3db0b3b4dfee54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T07:27:08.770720Z",
     "start_time": "2025-12-01T07:27:08.588480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x0_test = best_model.encoder_estim_x0(Y_test[:n_lag], U_test[:n_lag])\n",
    "Yhat_test_w_enc, _ = best_model.simulate(x0_test, U_test[n_lag:])  # keep in mind that now we will only simulate from time index n_lag\n",
    "error = RMS_error(Y_test[n_lag:], Yhat_test_w_enc)\n",
    "print(f'RMS error: {error:.4f}')"
   ],
   "id": "fe3c946b7dbbabb6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS error: 0.0989\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
