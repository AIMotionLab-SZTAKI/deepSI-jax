{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-10T10:13:56.630345Z",
     "start_time": "2025-07-10T10:13:55.464679Z"
    }
   },
   "source": [
    "import deepSI_jax\n",
    "from deepSI_jax import get_nu_ny_and_auto_norm\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data generation\n",
    "`deepSI-jax` uses IO data sequences gathered in separated `numpy` arrays with shapes N-by-nu and N-by-ny, where N is the length of the data sequence, nu is the input dimension, ny is the output dimension.\n",
    "\n",
    "If the training (or test) data-set consists of multiple measurement records, create a list of `numpy` arrays as shown below."
   ],
   "id": "f89d86363dd3772f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T10:13:57.473735Z",
     "start_time": "2025-07-10T10:13:57.425612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate or load data\n",
    "np.random.seed(0)  # for reproducibility\n",
    "U1 = np.random.randn(5000)  # Input sequence nr. 1\n",
    "x = [0, 0]  # Initial state\n",
    "ylist = []  # Output sequence\n",
    "for uk in U1:\n",
    "    ek = np.random.normal(loc=0, scale=0.05)\n",
    "    ylist.append(x[0] + ek)  # Compute output\n",
    "    x = x[0] / (1.2 + x[1]**2) + x[1] * 0.4, \\\n",
    "        x[1] / (1.2 + x[0]**2) + x[0] * 0.4 + uk  # Advance state\n",
    "Y1 = np.array(ylist)  # Output sequence nr. 1\n",
    "\n",
    "U2 = np.random.randn(5000)  # Input sequence nr. 2\n",
    "x = [0.01, 0]  # Initial state\n",
    "ylist = [] # Output sequence\n",
    "for uk in U2:\n",
    "    ek = np.random.normal(loc=0, scale=0.05)\n",
    "    ylist.append(x[0] + ek)  # Compute output\n",
    "    x = x[0] / (1.2 + x[1]**2) + x[1] * 0.4, \\\n",
    "        x[1] / (1.2 + x[0]**2) + x[0] * 0.4 + uk  # Advance state\n",
    "Y2 = np.array(ylist)  # Output sequence nr. 2\n",
    "\n",
    "# Split datasets\n",
    "Y_train = [Y1, Y2[:4000]]\n",
    "Y_test = Y2[4000:]\n",
    "U_train = [U1, U2[:4000]]\n",
    "U_test = U2[4000:]"
   ],
   "id": "7d361c61126ad39b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter selection and model creation\n",
    "### ANN-SS models\n",
    "The main objective of the `deepSI-jax` toolbox is to train discrete-time artificial neural network-based state-space models in the form of\n",
    "$$\\hat{x}_{k+1} = f_\\theta(\\hat{x}_k, u_k),$$\n",
    "$$\\hat{y}_{k} = h_\\theta(\\hat{x}_k, u_k),$$\n",
    "where $k$ is the time index, $\\hat{x}_k$ is the model state, $u_k$ is the control input, $\\hat{y}_k$ is the model output, furthermore $f$ and $h$ are implemented as feedforward ANNs with $\\theta$ containing their tunable parameters (weights and biases). In some special cases, an encoder network is also part of the model structure, but more on that later. This example script will show tha basics of creating and training ANN-SS model with the `deepSI-jax` toolbox.\n",
    "\n",
    "### IO dimensions and data normalization\n",
    "The input and output dimensions of the data-generating system, moreover the mean and standard deviation values (which is required for data normalization) are computed automatically by calling the `get_nu_ny_auto_norm` function. The `norm` object is a dictionary with entries `y_mean`, `y_std`, etc., which will later used for model creation."
   ],
   "id": "df6437f5894f56eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T10:14:00.538737Z",
     "start_time": "2025-07-10T10:14:00.522675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# hyperparameters and data normalization\n",
    "nu, ny, norm = get_nu_ny_and_auto_norm(Y_train, U_train)\n",
    "print(norm)"
   ],
   "id": "ef7b2e188f80648e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y_mean': array([-0.03780075]), 'y_std': array([0.76891903]), 'u_mean': array([-0.01014596]), 'u_std': array([0.99269028])}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Selecting the ANN structures\n",
    "The ANN structures can be defined by providing different dictionaries that contain the following entries:\n",
    "- `hidden_layers` : Number of hidden layers in the ANN.\n",
    "- `nodes_per_layer` : Number of nodes (neurons) of the hidden layers.\n",
    "- `activation` : Activation function of the ANN in a string form. Currently, the supported inputs are: `None` for linear activation, `\"relu\"` for rectified linear, `\"tanh\"` for hyperbolic tangent, `\"sigmoid\"` for the logistic function, and finally the `\"swish\"` activation.\n",
    "- `feedthrough` : only interpreted for the output map $h_\\theta$. If `feedthrough = True`, then $\\hat{y}_k = h_\\theta(\\hat{x}_k, u_k)$, otherwise the model output will not depend on the input value, as $\\hat{y}_k = h_\\theta(\\hat{x}_k)$.\n",
    "\n",
    "Each of these settings is optional, the default values are 2 hidden layers with 16 nodes per layer and the tanh activation function. For the output map, the default is `feedthrough = True`."
   ],
   "id": "8753d9db4ac1f079"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T10:14:03.348592Z",
     "start_time": "2025-07-10T10:14:03.332868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "f_dict = dict(hidden_layers=2, nodes_per_layer=32, activation='tanh')\n",
    "h_dict = dict(feedthrough=False)  # hidden_layers=2, nodes_per_layer=16, activation='tanh' by default"
   ],
   "id": "eebb8d29ff4d0618",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Other parameters\n",
    "The last parameters that need to be selected before creating the SUBNET model are:\n",
    "- `nx` : The dimension of the model state.\n",
    "- `seed` (optional): Seed number for initialization. Useful for reproducibility and selecting initial parameters that are closer to the global minima to prevent getting stuck at a local optimum.\n",
    "\n",
    "Further parameters are `use_encoder` and `encoder_lag`, but we will introduce them in the next example script. Then finally, the model can be simply initialized as shown below.\n"
   ],
   "id": "7fb65c8c4d15f51e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T10:14:06.494028Z",
     "start_time": "2025-07-10T10:14:05.364586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nx = 3\n",
    "model = deepSI_jax.SUBNET(nx=nx, ny=ny, nu=nu, norm=norm, f_args=f_dict, h_args=h_dict, use_encoder=False, seed=3)"
   ],
   "id": "e0820048ece0bbaa",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Loss function and optimization algorithm settings\n",
    "### Optional regularization terms\n",
    "Regularization terms can be added to the cost function by calling the `set_loss_fun` method of the model. It is possible to set the coefficients of $\\ell_1$ and $\\ell_2$ regularization on the model parameters $\\theta$, $\\ell_2$ regularization of the initial states $\\hat{x}_0$ (since they are co-estimated with $\\theta$ if no encoder function is used).\n",
    "\n",
    "Further (optional) inputs are:\n",
    "- `output_loss` : By default this is the root-mean-squared error of the simulated output, but custom function can also be provided (e.g., normalized RMSE) in the form of `loss=output_loss(Yhat,Y)`.\n",
    "- `group_lasso_reg` and `group_lasso_fcn` relate to group-lasso regularization for automatic model order selection and can be provided here. #TODO: group lasso function on x should be included in the model\n",
    "- `zero_coeff` : Model coefficient that are smaller in absolute value that `zero_coeff` are set to zero. Mostly useful when $\\ell_1$ or group-lasso regularization is applied.\n",
    "- `xsat` : State values are saturated at this value during training to prevent numerical issues. By default, this is not applied.\n",
    "- Other options are related to the truncated prediction loss, but more on them later."
   ],
   "id": "305fca13901f9185"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T10:14:09.135091Z",
     "start_time": "2025-07-10T10:14:09.127684Z"
    }
   },
   "cell_type": "code",
   "source": "model.set_loss_fun(l2_reg=1e-4, l1_reg=0., l2_reg_x0=1e-3)",
   "id": "51f4f839569ef844",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Optimization algorithm settings\n",
    "Lastly, the settings of the optimization algorithms need to be given by calling the `optimization` method of the model. The most important settings are the Adam and L-BFGS-B epochs, but specific parameters can be also set for each optimization algorithm and parameter bounds (box constraints) can be also defined."
   ],
   "id": "7f98a1a96c11ea01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T10:14:12.514641Z",
     "start_time": "2025-07-10T10:14:12.482760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.optimization(adam_epochs=200, lbfgs_epochs=200)  # only to run fast\n",
    "# model.optimization(adam_epochs=1000, lbfgs_epochs=5000)  # uncomment this for better results (~2.5-min training)"
   ],
   "id": "e9146532d48411bd",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model training\n",
    "After setting up the model and optimization parameters, the training can be started by calling the `fit` method."
   ],
   "id": "eb5f2fa0348e5099"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T10:14:27.236918Z",
     "start_time": "2025-07-10T10:14:14.672179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train model on data\n",
    "model.fit(Y_train, U_train)"
   ],
   "id": "c33c650dfb97bd78",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                        |\n",
      "\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving NLP with Adam (1689 optimization variables) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                        |1894, |grad f| =  5.592564, iter = 1\u001B[A\n",
      "    f =   3.344266, f* =  3.344266, |grad f| =  5.177081, iter = 2\u001B[A\n",
      "    f =   3.309425, f* =  3.309425, |grad f| =  4.908060, iter = 3\u001B[A\n",
      "  2%|▍                       |6601, |grad f| =  4.721327, iter = 4\u001B[A\n",
      "    f =   3.245332, f* =  3.245332, |grad f| =  4.600328, iter = 5\u001B[A\n",
      "    f =   3.215224, f* =  3.215224, |grad f| =  4.542352, iter = 6\u001B[A\n",
      "    f =   3.185871, f* =  3.185871, |grad f| =  4.557124, iter = 7\u001B[A\n",
      "  4%|▉                       |6857, |grad f| =  4.682057, iter = 8\u001B[A\n",
      "    f =   3.127764, f* =  3.127764, |grad f| =  4.885990, iter = 9\u001B[A\n",
      "    f =   3.098187, f* =  3.098187, |grad f| =  5.104783, iter = 10\u001B[A\n",
      "    f =   3.067735, f* =  3.067735, |grad f| =  5.327765, iter = 11\u001B[A\n",
      "  6%|█▍                      |6026, |grad f| =  5.555974, iter = 12\u001B[A\n",
      "    f =   3.002685, f* =  3.002685, |grad f| =  5.792733, iter = 13\u001B[A\n",
      "    f =   2.967337, f* =  2.967337, |grad f| =  6.045295, iter = 14\u001B[A\n",
      "    f =   2.929610, f* =  2.929610, |grad f| =  6.358460, iter = 15\u001B[A\n",
      "  8%|█▉                      |9123, |grad f| =  6.708083, iter = 16\u001B[A\n",
      "    f =   2.845476, f* =  2.845476, |grad f| =  7.099482, iter = 17\u001B[A\n",
      "    f =   2.798233, f* =  2.798233, |grad f| =  7.600464, iter = 18\u001B[A\n",
      "    f =   2.746894, f* =  2.746894, |grad f| =  8.202043, iter = 19\u001B[A\n",
      " 10%|██▍                     |0863, |grad f| =  8.886065, iter = 20\u001B[A\n",
      "    f =   2.629417, f* =  2.629417, |grad f| =  9.650061, iter = 21\u001B[A\n",
      "    f =   2.561693, f* =  2.561693, |grad f| =  10.496999, iter = 22\u001B[A\n",
      "    f =   2.486682, f* =  2.486682, |grad f| =  11.435789, iter = 23\u001B[A\n",
      " 12%|██▉                     |3213, |grad f| =  12.481491, iter = 24\u001B[A\n",
      "    f =   2.309920, f* =  2.309920, |grad f| =  13.654612, iter = 25\u001B[A\n",
      "    f =   2.205190, f* =  2.205190, |grad f| =  14.979993, iter = 26\u001B[A\n",
      "    f =   2.087120, f* =  2.087120, |grad f| =  16.484595, iter = 27\u001B[A\n",
      " 14%|███▎                    |3491, |grad f| =  18.192747, iter = 28\u001B[A\n",
      "    f =   1.801810, f* =  1.801810, |grad f| =  20.115644, iter = 29\u001B[A\n",
      "    f =   1.629490, f* =  1.629490, |grad f| =  22.228236, iter = 30\u001B[A\n",
      "    f =   1.434336, f* =  1.434336, |grad f| =  24.420301, iter = 31\u001B[A\n",
      " 16%|███▊                    |5682, |grad f| =  26.395291, iter = 32\u001B[A\n",
      "    f =   0.976960, f* =  0.976960, |grad f| =  27.439544, iter = 33\u001B[A\n",
      "    f =   0.732118, f* =  0.732118, |grad f| =  25.725773, iter = 34\u001B[A\n",
      "    f =   0.525452, f* =  0.525452, |grad f| =  17.043764, iter = 35\u001B[A\n",
      " 18%|████▎                   |7004, |grad f| =  24.011552, iter = 36\u001B[A\n",
      "    f =   0.650663, f* =  0.477004, |grad f| =  51.651780, iter = 37\u001B[A\n",
      "    f =   0.690413, f* =  0.477004, |grad f| =  64.104717, iter = 38\u001B[A\n",
      "    f =   0.556941, f* =  0.477004, |grad f| =  51.721865, iter = 39\u001B[A\n",
      " 20%|████▊                   |9458, |grad f| =  27.531936, iter = 40\u001B[A\n",
      "    f =   0.324073, f* =  0.324073, |grad f| =  9.071093, iter = 41 \u001B[A\n",
      "    f =   0.323590, f* =  0.323590, |grad f| =  7.899161, iter = 42\u001B[A\n",
      "    f =   0.362857, f* =  0.323590, |grad f| =  14.518061, iter = 43\u001B[A\n",
      " 22%|█████▎                  |3590, |grad f| =  18.617188, iter = 44\u001B[A\n",
      "    f =   0.443775, f* =  0.323590, |grad f| =  19.705661, iter = 45\u001B[A\n",
      "    f =   0.459972, f* =  0.323590, |grad f| =  20.298036, iter = 46\u001B[A\n",
      "    f =   0.457622, f* =  0.323590, |grad f| =  20.925460, iter = 47\u001B[A\n",
      " 24%|█████▊                  |3590, |grad f| =  20.522391, iter = 48\u001B[A\n",
      "    f =   0.405813, f* =  0.323590, |grad f| =  18.605330, iter = 49\u001B[A\n",
      "    f =   0.367945, f* =  0.323590, |grad f| =  14.967695, iter = 50\u001B[A\n",
      "    f =   0.334630, f* =  0.323590, |grad f| =  11.394738, iter = 51\u001B[A\n",
      " 26%|██████▏                 |4562, |grad f| =  7.444786, iter = 52 \u001B[A\n",
      "    f =   0.312696, f* =  0.312696, |grad f| =  10.351496, iter = 53\u001B[A\n",
      "    f =   0.325868, f* =  0.312696, |grad f| =  16.655933, iter = 54\u001B[A\n",
      "    f =   0.338648, f* =  0.312696, |grad f| =  21.216332, iter = 55\u001B[A\n",
      " 28%|██████▋                 |2696, |grad f| =  22.018188, iter = 56\u001B[A\n",
      "    f =   0.317749, f* =  0.312696, |grad f| =  18.778542, iter = 57\u001B[A\n",
      "    f =   0.294737, f* =  0.294737, |grad f| =  12.437894, iter = 58\u001B[A\n",
      "    f =   0.278619, f* =  0.278619, |grad f| =  5.747237, iter = 59 \u001B[A\n",
      " 30%|███████▏                |3500, |grad f| =  2.467460, iter = 60\u001B[A\n",
      "    f =   0.276730, f* =  0.273500, |grad f| =  5.410799, iter = 61\u001B[A\n",
      "    f =   0.283115, f* =  0.273500, |grad f| =  8.113178, iter = 62\u001B[A\n",
      "    f =   0.288128, f* =  0.273500, |grad f| =  9.773679, iter = 63\u001B[A\n",
      " 32%|███████▋                |3500, |grad f| =  10.428280, iter = 64\u001B[A\n",
      "    f =   0.285368, f* =  0.273500, |grad f| =  10.110100, iter = 65\u001B[A\n",
      "    f =   0.277806, f* =  0.273500, |grad f| =  8.856007, iter = 66 \u001B[A\n",
      "    f =   0.268581, f* =  0.268581, |grad f| =  6.772670, iter = 67\u001B[A\n",
      " 34%|████████▏               |0373, |grad f| =  4.202631, iter = 68\u001B[A\n",
      "    f =   0.255450, f* =  0.255450, |grad f| =  2.725142, iter = 69\u001B[A\n",
      "    f =   0.254490, f* =  0.254490, |grad f| =  4.457022, iter = 70\u001B[A\n",
      "    f =   0.255776, f* =  0.254490, |grad f| =  7.024518, iter = 71\u001B[A\n",
      " 36%|████████▋               |4490, |grad f| =  8.675862, iter = 72\u001B[A\n",
      "    f =   0.253076, f* =  0.253076, |grad f| =  8.673319, iter = 73\u001B[A\n",
      "    f =   0.247184, f* =  0.247184, |grad f| =  7.092177, iter = 74\u001B[A\n",
      "    f =   0.240918, f* =  0.240918, |grad f| =  4.581267, iter = 75\u001B[A\n",
      " 38%|█████████               |6671, |grad f| =  2.197419, iter = 76\u001B[A\n",
      "    f =   0.235085, f* =  0.235085, |grad f| =  2.331786, iter = 77\u001B[A\n",
      "    f =   0.235123, f* =  0.235085, |grad f| =  3.992483, iter = 78\u001B[A\n",
      "    f =   0.235149, f* =  0.235085, |grad f| =  5.146584, iter = 79\u001B[A\n",
      " 40%|█████████▌              |3929, |grad f| =  5.481798, iter = 80\u001B[A\n",
      "    f =   0.231166, f* =  0.231166, |grad f| =  5.012349, iter = 81\u001B[A\n",
      "    f =   0.227482, f* =  0.227482, |grad f| =  3.895235, iter = 82\u001B[A\n",
      "    f =   0.223975, f* =  0.223975, |grad f| =  2.444875, iter = 83\u001B[A\n",
      " 42%|██████████              |1556, |grad f| =  2.012586, iter = 84\u001B[A\n",
      "    f =   0.220336, f* =  0.220336, |grad f| =  3.427618, iter = 85\u001B[A\n",
      "    f =   0.219520, f* =  0.219520, |grad f| =  4.744045, iter = 86\u001B[A\n",
      "    f =   0.218056, f* =  0.218056, |grad f| =  5.201739, iter = 87\u001B[A\n",
      " 44%|██████████▌             |5545, |grad f| =  4.656349, iter = 88\u001B[A\n",
      "    f =   0.212526, f* =  0.212526, |grad f| =  3.347296, iter = 89\u001B[A\n",
      "    f =   0.209887, f* =  0.209887, |grad f| =  1.911886, iter = 90\u001B[A\n",
      "    f =   0.208086, f* =  0.208086, |grad f| =  1.608161, iter = 91\u001B[A\n",
      " 46%|███████████             |6905, |grad f| =  2.240631, iter = 92\u001B[A\n",
      "    f =   0.205777, f* =  0.205777, |grad f| =  2.771704, iter = 93\u001B[A\n",
      "    f =   0.204259, f* =  0.204259, |grad f| =  2.842573, iter = 94\u001B[A\n",
      "    f =   0.202312, f* =  0.202312, |grad f| =  2.429109, iter = 95\u001B[A\n",
      " 48%|███████████▌            |0252, |grad f| =  1.702744, iter = 96\u001B[A\n",
      "    f =   0.198478, f* =  0.198478, |grad f| =  1.316595, iter = 97\u001B[A\n",
      "    f =   0.197143, f* =  0.197143, |grad f| =  1.735870, iter = 98\u001B[A\n",
      "    f =   0.196030, f* =  0.196030, |grad f| =  2.400660, iter = 99\u001B[A\n",
      " 50%|████████████            |4758, |grad f| =  2.693004, iter = 100\u001B[A\n",
      "    f =   0.193147, f* =  0.193147, |grad f| =  2.447656, iter = 101\u001B[A\n",
      "    f =   0.191381, f* =  0.191381, |grad f| =  1.801501, iter = 102\u001B[A\n",
      "    f =   0.189778, f* =  0.189778, |grad f| =  1.241979, iter = 103\u001B[A\n",
      " 52%|████████████▍           |8470, |grad f| =  1.288418, iter = 104\u001B[A\n",
      "    f =   0.187324, f* =  0.187324, |grad f| =  1.606717, iter = 105\u001B[A\n",
      "    f =   0.186114, f* =  0.186114, |grad f| =  1.773781, iter = 106\u001B[A\n",
      "    f =   0.184741, f* =  0.184741, |grad f| =  1.635186, iter = 107\u001B[A\n",
      " 54%|████████████▉           |3298, |grad f| =  1.302241, iter = 108\u001B[A\n",
      "    f =   0.181963, f* =  0.181963, |grad f| =  1.125806, iter = 109\u001B[A\n",
      "    f =   0.180818, f* =  0.180818, |grad f| =  1.392438, iter = 110\u001B[A\n",
      "    f =   0.179768, f* =  0.179768, |grad f| =  1.780955, iter = 111\u001B[A\n",
      " 56%|█████████████▍          |8656, |grad f| =  1.887461, iter = 112\u001B[A\n",
      "    f =   0.177435, f* =  0.177435, |grad f| =  1.634064, iter = 113\u001B[A\n",
      "    f =   0.176210, f* =  0.176210, |grad f| =  1.226402, iter = 114\u001B[A\n",
      "    f =   0.175092, f* =  0.175092, |grad f| =  1.049824, iter = 115\u001B[A\n",
      " 58%|█████████████▉          |4079, |grad f| =  1.155077, iter = 116\u001B[A\n",
      "    f =   0.173077, f* =  0.173077, |grad f| =  1.262628, iter = 117\u001B[A\n",
      "    f =   0.172022, f* =  0.172022, |grad f| =  1.203009, iter = 118\u001B[A\n",
      "    f =   0.170941, f* =  0.170941, |grad f| =  1.019792, iter = 119\u001B[A\n",
      " 60%|██████████████▍         |9913, |grad f| =  0.925503, iter = 120\u001B[A\n",
      "    f =   0.168973, f* =  0.168973, |grad f| =  1.047513, iter = 121\u001B[A\n",
      "    f =   0.168078, f* =  0.168078, |grad f| =  1.213453, iter = 122\u001B[A\n",
      "    f =   0.167165, f* =  0.167165, |grad f| =  1.208381, iter = 123\u001B[A\n",
      " 62%|██████████████▉         |6231, |grad f| =  1.014517, iter = 124\u001B[A\n",
      "    f =   0.165328, f* =  0.165328, |grad f| =  0.837293, iter = 125\u001B[A\n",
      "    f =   0.164487, f* =  0.164487, |grad f| =  0.832980, iter = 126\u001B[A\n",
      "    f =   0.163684, f* =  0.163684, |grad f| =  0.906997, iter = 127\u001B[A\n",
      " 64%|███████████████▎        |2878, |grad f| =  0.915232, iter = 128\u001B[A\n",
      "    f =   0.162065, f* =  0.162065, |grad f| =  0.825388, iter = 129\u001B[A\n",
      "    f =   0.161273, f* =  0.161273, |grad f| =  0.738289, iter = 130\u001B[A\n",
      "    f =   0.160527, f* =  0.160527, |grad f| =  0.757364, iter = 131\u001B[A\n",
      " 66%|███████████████▊        |9815, |grad f| =  0.837739, iter = 132\u001B[A\n",
      "    f =   0.159112, f* =  0.159112, |grad f| =  0.844095, iter = 133\u001B[A\n",
      "    f =   0.158411, f* =  0.158411, |grad f| =  0.753537, iter = 134\u001B[A\n",
      "    f =   0.157731, f* =  0.157731, |grad f| =  0.658219, iter = 135\u001B[A\n",
      " 68%|████████████████▎       |7086, |grad f| =  0.648400, iter = 136\u001B[A\n",
      "    f =   0.156466, f* =  0.156466, |grad f| =  0.680977, iter = 137\u001B[A\n",
      "    f =   0.155853, f* =  0.155853, |grad f| =  0.676719, iter = 138\u001B[A\n",
      "    f =   0.155245, f* =  0.155245, |grad f| =  0.625572, iter = 139\u001B[A\n",
      " 70%|████████████████▊       |4654, |grad f| =  0.579309, iter = 140\u001B[A\n",
      "    f =   0.154088, f* =  0.154088, |grad f| =  0.591149, iter = 141\u001B[A\n",
      "    f =   0.153539, f* =  0.153539, |grad f| =  0.623360, iter = 142\u001B[A\n",
      "    f =   0.152998, f* =  0.152998, |grad f| =  0.610843, iter = 143\u001B[A\n",
      " 72%|█████████████████▎      |2465, |grad f| =  0.560838, iter = 144\u001B[A\n",
      "    f =   0.151948, f* =  0.151948, |grad f| =  0.530912, iter = 145\u001B[A\n",
      "    f =   0.151448, f* =  0.151448, |grad f| =  0.546198, iter = 146\u001B[A\n",
      "    f =   0.150961, f* =  0.150961, |grad f| =  0.567510, iter = 147\u001B[A\n",
      " 74%|█████████████████▊      |0481, |grad f| =  0.555182, iter = 148\u001B[A\n",
      "    f =   0.150008, f* =  0.150008, |grad f| =  0.520955, iter = 149\u001B[A\n",
      "    f =   0.149547, f* =  0.149547, |grad f| =  0.501047, iter = 150\u001B[A\n",
      "    f =   0.149099, f* =  0.149099, |grad f| =  0.507882, iter = 151\u001B[A\n",
      " 76%|██████████████████▏     |8658, |grad f| =  0.509655, iter = 152\u001B[A\n",
      "    f =   0.148223, f* =  0.148223, |grad f| =  0.493216, iter = 153\u001B[A\n",
      "    f =   0.147794, f* =  0.147794, |grad f| =  0.470752, iter = 154\u001B[A\n",
      "    f =   0.147376, f* =  0.147376, |grad f| =  0.471761, iter = 155\u001B[A\n",
      " 78%|██████████████████▋     |6966, |grad f| =  0.481954, iter = 156\u001B[A\n",
      "    f =   0.146561, f* =  0.146561, |grad f| =  0.478074, iter = 157\u001B[A\n",
      "    f =   0.146160, f* =  0.146160, |grad f| =  0.455225, iter = 158\u001B[A\n",
      "    f =   0.145766, f* =  0.145766, |grad f| =  0.433068, iter = 159\u001B[A\n",
      " 80%|███████████████████▏    |5378, |grad f| =  0.425992, iter = 160\u001B[A\n",
      "    f =   0.144996, f* =  0.144996, |grad f| =  0.425005, iter = 161\u001B[A\n",
      "    f =   0.144618, f* =  0.144618, |grad f| =  0.418083, iter = 162\u001B[A\n",
      "    f =   0.144243, f* =  0.144243, |grad f| =  0.409109, iter = 163\u001B[A\n",
      " 82%|███████████████████▋    |3874, |grad f| =  0.412668, iter = 164\u001B[A\n",
      "    f =   0.143509, f* =  0.143509, |grad f| =  0.421489, iter = 165\u001B[A\n",
      "    f =   0.143148, f* =  0.143148, |grad f| =  0.425402, iter = 166\u001B[A\n",
      "    f =   0.142789, f* =  0.142789, |grad f| =  0.414421, iter = 167\u001B[A\n",
      " 84%|████████████████████▏   |2434, |grad f| =  0.412034, iter = 168\u001B[A\n",
      "    f =   0.142083, f* =  0.142083, |grad f| =  0.410865, iter = 169\u001B[A\n",
      "    f =   0.141735, f* =  0.141735, |grad f| =  0.446404, iter = 170\u001B[A\n",
      "    f =   0.141391, f* =  0.141391, |grad f| =  0.490430, iter = 171\u001B[A\n",
      " 86%|████████████████████▋   |1051, |grad f| =  0.629493, iter = 172\u001B[A\n",
      "    f =   0.140721, f* =  0.140721, |grad f| =  0.843416, iter = 173\u001B[A\n",
      "    f =   0.140418, f* =  0.140418, |grad f| =  1.373573, iter = 174\u001B[A\n",
      "    f =   0.140194, f* =  0.140194, |grad f| =  2.224921, iter = 175\u001B[A\n",
      " 88%|█████████████████████   |0194, |grad f| =  4.034314, iter = 176\u001B[A\n",
      "    f =   0.141116, f* =  0.140194, |grad f| =  8.130918, iter = 177\u001B[A\n",
      "    f =   0.144510, f* =  0.140194, |grad f| =  11.285957, iter = 178\u001B[A\n",
      "    f =   0.140473, f* =  0.140194, |grad f| =  7.466461, iter = 179 \u001B[A\n",
      " 90%|█████████████████████▌  |8763, |grad f| =  2.457465, iter = 180\u001B[A\n",
      "    f =   0.140260, f* =  0.138763, |grad f| =  7.795128, iter = 181\u001B[A\n",
      "    f =   0.138453, f* =  0.138453, |grad f| =  4.102336, iter = 182\u001B[A\n",
      "    f =   0.138012, f* =  0.138012, |grad f| =  3.787163, iter = 183\u001B[A\n",
      " 92%|██████████████████████  |8012, |grad f| =  6.686224, iter = 184\u001B[A\n",
      "    f =   0.137185, f* =  0.137185, |grad f| =  2.529238, iter = 185\u001B[A\n",
      "    f =   0.137377, f* =  0.137185, |grad f| =  4.752731, iter = 186\u001B[A\n",
      "    f =   0.137402, f* =  0.137185, |grad f| =  5.417247, iter = 187\u001B[A\n",
      " 94%|██████████████████████▌ |6171, |grad f| =  1.006746, iter = 188\u001B[A\n",
      "    f =   0.136749, f* =  0.136171, |grad f| =  4.970773, iter = 189\u001B[A\n",
      "    f =   0.135796, f* =  0.135796, |grad f| =  2.616072, iter = 190\u001B[A\n",
      "    f =   0.135700, f* =  0.135700, |grad f| =  3.452731, iter = 191\u001B[A\n",
      " 96%|███████████████████████ |5544, |grad f| =  4.037712, iter = 192\u001B[A\n",
      "    f =   0.134782, f* =  0.134782, |grad f| =  1.148118, iter = 193\u001B[A\n",
      "    f =   0.135002, f* =  0.134782, |grad f| =  3.781439, iter = 194\u001B[A\n",
      "    f =   0.134232, f* =  0.134232, |grad f| =  1.169478, iter = 195\u001B[A\n",
      " 98%|███████████████████████▌|4232, |grad f| =  2.917325, iter = 196\u001B[A\n",
      "    f =   0.133830, f* =  0.133830, |grad f| =  2.306985, iter = 197\u001B[A\n",
      "    f =   0.133523, f* =  0.133523, |grad f| =  2.070046, iter = 198\u001B[A\n",
      "    f =   0.133354, f* =  0.133354, |grad f| =  2.513402, iter = 199\u001B[A\n",
      "100%|████████████████████████|2862, |grad f| =  0.883127, iter = 200\u001B[A\n",
      "    f =   0.132862, f* =  0.132862, |grad f| =  0.883127, iter = 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving NLP with L-BFGS (1689 optimization variables) ...\n",
      "L-BFGS-B done in 171 iterations.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T10:14:36.839627Z",
     "start_time": "2025-07-10T10:14:36.807641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "t0 = model.t_solve\n",
    "print(f\"Elapsed time: {t0} s\")"
   ],
   "id": "af62e7e0f3b246ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 12.545217275619507 s\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Evaluating the trained models on new (test) data\n",
    "To simulate the model using new data, simply call `model.simulate`. To do so, it is necessary to provide an initial state value. If the model does not contain an encoder network, an optimization-based initial state estimation can be applied by running the `learn_x0` method of the model."
   ],
   "id": "589114065582f264"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T10:57:47.060479Z",
     "start_time": "2025-07-10T10:57:46.353861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n = 20  # state initialization window\n",
    "x0_test = model.learn_x0(U_test[:n], Y_test[:n], RTS_epochs=10, LBFGS_refinement=True, verbosity=False)\n",
    "Yhat_test, _ = model.simulate(x0_test, U_test)"
   ],
   "id": "eb2d9aea94745e44",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For model evaluations, the `deepSI_jax.utils` file contains various error metrics.",
   "id": "95b1921e869d2080"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from deepSI_jax.utils import NRMS_error\n",
    "# only evaluate the part that was not used for estimating x0\n",
    "nrmse = NRMS_error(Y_test[n:], Yhat_test[n:, 0])  # 1.98%\n",
    "\n",
    "sim_idx = np.arange(U_test.shape[0])\n",
    "# Visualize simulation of the model\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.plot(sim_idx, Y_test, label='Real Data')\n",
    "plt.plot(sim_idx[n:], Yhat_test[n:, 0], label=f'Model Sim. (NRMS = {nrmse:.2%})', linestyle='--')\n",
    "plt.title('Comparison of Real Data and Model Simulation', fontsize=14, fontweight='bold')\n",
    "plt.legend(); plt.xlabel('Time Index'); plt.ylabel('y'); plt.grid(); plt.tight_layout(pad=0.5)\n",
    "plt.show()"
   ],
   "id": "4fbae5f38b79bf61"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
